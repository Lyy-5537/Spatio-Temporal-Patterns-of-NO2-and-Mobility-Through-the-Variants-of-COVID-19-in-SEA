{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e24a9195",
   "metadata": {},
   "source": [
    "<font face=\"Times New Roman\" size=6 >\n",
    "GE5219 Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb540160",
   "metadata": {},
   "source": [
    "# Facebook Movement between Tiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058750fc",
   "metadata": {},
   "source": [
    "## Source Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e030a985",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "import datetime\n",
    "from datetime import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80795964",
   "metadata": {},
   "source": [
    "### Read File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95b1fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = r\"E:\\GRADUATE STUDY\\GE5219\\Data\\Trial\\movement\\2662837396048326_2020-03-26_1600.csv\"\n",
    "df = pd.read_csv(filepath)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8161b7bc",
   "metadata": {},
   "source": [
    "### Merge File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d17225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up variables\n",
    "path = 'E://GRADUATE STUDY//GE5219//Data//Movement//202003'  # Folder Path\n",
    "filename_extenstion = '.csv'  # File extension\n",
    "file_allname = []  # Store all file names ready for merge\n",
    "cols_new_name = ['geometry', 'date_time', 'length_km', 'country', 'n_crisis','baseline','difference','percentage','z_score','start_lat','start_lon','end_lat','end_lon']\n",
    "cols_num = [0, 1, 6, 8, 10, 11, 12, 13, 15, 16, 17, 18, 19]  # Index of columns that are ready for merge, starting from 0\n",
    "\n",
    "\n",
    "# list file names\n",
    "for filename in os.listdir(path): # look for files in the folder\n",
    "    if os.path.splitext(filename)[1] == filename_extenstion:\n",
    "        t = os.path.splitext(filename)[0]\n",
    "        file_allname.append(path + '/' + t + filename_extenstion)  # restore csv suffix\n",
    "        \n",
    "df = pd.DataFrame(cols_new_name).T\n",
    "df.to_csv(\"temp.csv\", header=False, index=False)\n",
    "for fn in file_allname:\n",
    "    data = pd.read_csv(fn)\n",
    "    data = data.iloc[1:, cols_num]\n",
    "    data.to_csv(\"temp.csv\", mode='a', header=False, index=False)\n",
    "\n",
    "# Auto Rename\n",
    "os.rename(\"temp.csv\",data.iloc[1,1].split(\"-\")[0] + data.iloc[1,1].split(\"-\")[1] + \".csv\")\n",
    "print('Merge Complete')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104240ae",
   "metadata": {},
   "source": [
    "### Remove Rebundant Countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c22ab55",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filepath = \"202003.csv\"\n",
    "df1 = pd.read_csv(filepath)\n",
    "df2 = df1.loc[(df1['country'] == 'SG') | (df1['country'] == 'VN')]\n",
    "\n",
    "# AGGREGATE BY DAY\n",
    "aggregate_column = ['length_km','n_crisis']\n",
    "\n",
    "# Split date and time\n",
    "date = df2['date_time'].str.split('-', expand=True)\n",
    "time = date[2].str.split(' ', expand=True)\n",
    "split_data = pd.concat([df2, date[[0,1]], time], axis = 1)\n",
    "\n",
    "# Fill in NaN\n",
    "split_data.loc[:,['n_crisis','baseline']] = split_data.loc[:,['n_crisis','baseline']].fillna(5)\n",
    "\n",
    "# Rename columns\n",
    "def df_column_uniquify(df):\n",
    "    df_columns = df.columns\n",
    "    new_columns = []\n",
    "    for item in df_columns:\n",
    "        counter = 0\n",
    "        newitem = item\n",
    "        while newitem in new_columns:\n",
    "            counter += 1\n",
    "            newitem = \"{}_{}\".format(item, counter)\n",
    "        new_columns.append(newitem)\n",
    "    df.columns = new_columns\n",
    "    return df\n",
    "\n",
    "df_column_uniquify(split_data)\n",
    "\n",
    "split_data.rename(columns={0:\"year\",1:\"month\",\"0_1\":\"day\",\"1_1\":\"time\"}, inplace=True)\n",
    "\n",
    "# Aggregate by time\n",
    "aggregate_value = ['n_crisis','difference','baseline']\n",
    "aggregate = split_data.groupby(['country','start_lat','start_lon','end_lat','end_lon','year','month','day'])[aggregate_value].sum()\n",
    "aggregate = aggregate.reset_index() # return dataframe of groupby result\n",
    "\n",
    "# CALCULATE which GRID the trajectory is in, the grid index starts from 0\n",
    "startgrid_x = []\n",
    "startgrid_y = []\n",
    "endgrid_x = []\n",
    "endgrid_y = []\n",
    "dif_x = []\n",
    "dif_y = []\n",
    "\n",
    "for index, row in aggregate.iterrows():\n",
    "    startgridx = math.floor((row['start_lon'] - 92.25)/0.25)\n",
    "    startgridy = math.floor((28.5 - row['start_lat'])/0.25)\n",
    "    endgridx = math.floor((row['end_lon'] - 92.25)/0.25)\n",
    "    endgridy = math.floor((28.5 - row['end_lat'])/0.25)\n",
    "    difx = abs(startgridx - endgridx)\n",
    "    dify = abs(startgridy - endgridy)\n",
    "    \n",
    "    startgrid_x.append(startgridx)\n",
    "    startgrid_y.append(startgridy)\n",
    "    endgrid_x.append(endgridx)\n",
    "    endgrid_y.append(endgridy)\n",
    "    dif_x.append(difx)\n",
    "    dif_y.append(dify)\n",
    "\n",
    "grid = pd.DataFrame({\"startgrid_x\":startgrid_x,\n",
    "                    \"startgrid_y\":startgrid_y,\n",
    "                    \"endgrid_x\":endgrid_x,\n",
    "                    \"endgrid_y\":endgrid_y,\n",
    "                    \"dif_x\":dif_x,\n",
    "                    \"dif_y\":dif_y})\n",
    "\n",
    "with_grid = pd.concat([aggregate, grid], axis = 1)\n",
    "\n",
    "# Filter those data not within one or two adjacent grid\n",
    "with_grid.drop(with_grid[(with_grid['dif_x']>1) | (with_grid['dif_y']>1)].index,axis=0, inplace = True)\n",
    "\n",
    "# AGGREGATE BY GRID\n",
    "aggregate_value = ['n_crisis','difference','baseline']\n",
    "aggregate2 = with_grid.groupby(['country','year','month','day','startgrid_x','startgrid_y','endgrid_x','endgrid_y'])[aggregate_value].sum()\n",
    "aggregate2 = aggregate2.reset_index() # return dataframe of groupby result\n",
    "date = aggregate2['year'].str.cat(aggregate2['month'],sep='-').str.cat(aggregate2['day'],sep='-')\n",
    "aggregate2 = aggregate2.drop(['year','month','day'], axis = 1)\n",
    "aggregate2 = pd.concat([aggregate2, date], axis = 1)\n",
    "aggregate2.to_csv(\"aggtemp.csv\", mode='a', header=True, index=False)\n",
    "\n",
    "# Auto rename\n",
    "os.rename(\"aggtemp.csv\",\"Agg\" + aggregate2.iloc[0,1] + aggregate2.iloc[0,2] + \".csv\")\n",
    "print('Aggregate Complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cada8018",
   "metadata": {},
   "source": [
    "### Assign Value to Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b13ded4",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"Agg202003.csv\"\n",
    "df3 = pd.read_csv(filepath)\n",
    "df3.eval('movement_value = n_crisis / 2' , inplace=True)\n",
    "df4 = df3.drop([\"endgrid_x\",\"endgrid_y\"], axis = 1)\n",
    "df5 = df3.drop([\"startgrid_x\",\"startgrid_y\"], axis = 1)\n",
    "df4.rename(columns={\"startgrid_x\":\"grid_x\", \"startgrid_y\":\"grid_y\"}, inplace = True)\n",
    "df5.rename(columns={\"endgrid_x\":\"grid_x\", \"endgrid_y\":\"grid_y\"}, inplace = True)\n",
    "Cal_grid = pd.concat([df4, df5], axis = 0)\n",
    "Cal_grid = Cal_grid.reset_index()\n",
    "Cal_grid.to_csv(\"gridtemp.csv\", mode='a', header=True, index=False)\n",
    "\n",
    "# Auto rename\n",
    "os.rename(\"gridtemp.csv\",\"Grid\" + str(Cal_grid.iloc[0,2]) + str(Cal_grid.iloc[0,3]) + \".csv\")\n",
    "print('Generate Grid Complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcec5e26",
   "metadata": {},
   "source": [
    "### Merge Files From All Countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08de8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up variables\n",
    "path = r'E:\\GRADUATE STUDY\\GE5219\\Data\\Movement\\Results\\Processed data'  # Folder Path\n",
    "filename_extenstion = '.csv'  # File extension\n",
    "cols_new_name = [\"country\",\"date\",\"grid_x\",\"grid_y\",\"n_crisis\",\"difference\",\"baseline\",\"movement_value\",\"grid_lon\",\"grid_lat\"]  # column names after merging, modify according to needs\n",
    "\n",
    "# list file names\n",
    "for year in range(2020,2023):\n",
    "    for month in range(1,13):\n",
    "        if year == 2020 and month<3:\n",
    "            continue\n",
    "        elif year == 2022 and month>2:\n",
    "            break\n",
    "        else:\n",
    "            file_allname = []  # Store all file names ready for merge\n",
    "            for filename in os.listdir(path): # look for files in the folder\n",
    "                if os.path.splitext(filename)[1] == filename_extenstion and \"Grid\" in filename and \"{}{:0>2d}\".format(year, month) in filename: \n",
    "                    t = os.path.splitext(filename)[0]\n",
    "                    file_allname.append(path + '/' + t + filename_extenstion)  # restore csv suffix\n",
    "\n",
    "            df = pd.DataFrame(cols_new_name).T\n",
    "            df.to_csv(\"temp.csv\", header=False, index=False) \n",
    "\n",
    "            for fn in file_allname:\n",
    "                data = pd.read_csv(fn)\n",
    "                data = data.iloc[1:,0:10]\n",
    "                data.to_csv(\"temp.csv\", mode='a', header=False, index=False)\n",
    "\n",
    "            # auto rename\n",
    "            os.rename(\"temp.csv\",\"{}.{:0>2d}.csv\".format(year,month))\n",
    "            print(\"Merge Complete {}.{:0>2d}.csv\".format(year,month))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e09e91",
   "metadata": {},
   "source": [
    "### Drop Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6d87df",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = r\"E:\\GRADUATE STUDY\\GE5219\\Data\\Study Area\\Study Area Refined.csv\"\n",
    "dp = pd.read_csv(filepath)\n",
    "dp2 = dp.drop_duplicates()\n",
    "dp2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7fab1c",
   "metadata": {},
   "source": [
    "### For Case Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2919ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate monthly data\n",
    "folder_path = \"E:\\GRADUATE STUDY\\GE5219\\Data\\Movement\\Results\\Processed data\"\n",
    "for filename in os.listdir(folder_path):\n",
    "    if \"GridID\" in filename or \"GridSG\" in filename:\n",
    "        df = pd.read_csv(folder_path + \"\\\\\" + filename, header = 0)\n",
    "        df = df.groupby(['grid_lon','grid_lat','country']).mean(['n_crisis','difference','baseline','movement_value'])\n",
    "        df = df.reset_index()\n",
    "        df['date']= filename[6:12]\n",
    "        df.to_csv(filename[4:], columns = ['grid_lon','grid_lat','movement_value','date','country'], index = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9ba794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge monthly country data\n",
    "folder_path = \"E:\\GRADUATE STUDY\\GE5219\\Data\\Movement\\Results\\Monthly\"\n",
    "SG = []\n",
    "ID = []\n",
    "for filename in os.listdir(folder_path):\n",
    "    df = pd.read_csv(folder_path + \"\\\\\" + filename, header = 0)\n",
    "    if \"SG\" in filename:\n",
    "        SG.append(df)\n",
    "    if \"ID\" in filename:\n",
    "        ID.append(df)\n",
    "SG = pd.concat(SG)\n",
    "SG[\"country\"].fillna((\"SG\"), inplace = True)\n",
    "ID = pd.concat(ID)\n",
    "ID[\"country\"].fillna((\"ID\"), inplace = True)\n",
    "Merge = pd.concat([ID,SG], axis = 0)\n",
    "SG.to_csv('SG.csv', index = 0)\n",
    "ID.to_csv('ID.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e1e213",
   "metadata": {},
   "outputs": [],
   "source": [
    "Merge['date'] = Merge['date'].map(lambda x: datetime.datetime.strptime(str(x), '%Y%m'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a514a4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Merge.to_csv(\"Space-time Analysis.csv\", index = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b214d292",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5e78d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate by month\n",
    "folder_path = \"E:\\GRADUATE STUDY\\GE5219\\Data\\Movement\\Results\\Exclude all months with abnormal value\"\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    df = pd.read_csv(folder_path + \"\\\\\" + filename, header = 0)\n",
    "    if '-' in df['date']:\n",
    "        date = df['date'].str.split('-', expand=False)\n",
    "    elif '/' in df['date']:\n",
    "        date = df['date'].str.split('/', expand=False)\n",
    "    print(date)\n",
    "    date = df['0'].str.cat(df['1'],sep='/')\n",
    "    print(date)\n",
    "#     split_df = pd.concat([df, date], axis = 1)\n",
    "#     print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec6eeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    aggregate = df.groupby(date.Grouper(freq='M'))['n_crisis','difference','baseline','movement_value'].sum()\n",
    "#    aggregate = df.groupby(['country','grid_x','grid_y','grid_lon','grid_lat', pd.Grouper(freq='M')])['n_crisis','difference','baseline','movement_value'].sum()\n",
    "    df = aggregate.reset_index() # return dataframe of groupby result\n",
    "    date = aggregate2['year'].str.cat(aggregate2['month'],sep='-').str.cat(aggregate2['day'],sep='-')\n",
    "    aggregate3 = aggregate2.drop(['year','month','day'], axis = 1)\n",
    "    aggregate3 = pd.concat([aggregate3, date], axis = 1)\n",
    "    aggregate3.rename(columns={\"year\":\"date\"}, inplace=True)\n",
    "    \n",
    "    print(df)\n",
    "#     df.to_csv(\"temp.csv\", mode = 'a', header=True, index=False)\n",
    "#     os.rename(\"temp.csv\",filename)\n",
    "\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c06a525",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09b3d69c",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7682aea",
   "metadata": {},
   "source": [
    "### Make Folder Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59694c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Make_File_Path(filepath, countries_list):\n",
    "    file_path=os.path.abspath(filepath)\n",
    "    for country in countries_list:\n",
    "        for year in range(2020,2023):\n",
    "            for month in range(1,13):\n",
    "                if year==2020 and month<3:\n",
    "                    continue\n",
    "                elif year==2022 and month>2:\n",
    "                    break\n",
    "                else:\n",
    "                    file = \"{}{}{:0>2d}\".format(country,year,month)\n",
    "                    file_name=file_path + \"\\\\\"+file\n",
    "                    os.makedirs(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b682820b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Make_File_Path(\"E:\\GRADUATE STUDY\\GE5219\\Data\\Movement\",[\"Philippines\",\"Myanmar\",\"Cambodia\",\"Brunei\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cae9d5",
   "metadata": {},
   "source": [
    "### Process Mobility File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7be6aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Process_File(folder_path, country):\n",
    "    # MERGE FILE\n",
    "\n",
    "    # set up variables\n",
    "    filename_extenstion = '.csv'  # File extension\n",
    "    file_allname = []  # Store all file names ready for merge\n",
    "    cols_new_name = ['geometry', 'date_time', 'length_km', 'country', 'n_crisis','baseline','difference','percentage','z_score','start_lat','start_lon','end_lat','end_lon']  # 汇总后的列名，根据需要修改\n",
    "    cols_num = [0, 1, 6, 8, 10, 11, 12, 13, 15, 16, 17, 18, 19]  # Index of columns that are ready for merge, starting from 0\n",
    "\n",
    "\n",
    "    # list file names\n",
    "    for filename in os.listdir(folder_path): # look for files in the folder\n",
    "        if os.path.splitext(filename)[1] == filename_extenstion:\n",
    "            t = os.path.splitext(filename)[0]\n",
    "            file_allname.append(folder_path + '/' + t + filename_extenstion)  # restore csv suffix\n",
    "\n",
    "#    frame = pd.DataFrame(cols_new_name).T\n",
    "    data = []\n",
    "    \n",
    "    for filenames in file_allname:\n",
    "        df = pd.read_csv(filenames, header = 0)\n",
    "        df = df.iloc[0:, cols_num]\n",
    "        df.columns = df.columns.map(lambda x:x.lower())\n",
    "        data.append(df) \n",
    "\n",
    "    data = pd.concat(data)\n",
    "    data.columns = cols_new_name\n",
    "\n",
    "#    CODE USED TO GENERATE RAW DATA CSV:\n",
    "#    df = pd.DataFrame(cols_new_name).T\n",
    "#    df.to_csv(\"temp.csv\", header=False, index=False)\n",
    "#    for fn in file_allname:\n",
    "#       data = pd.read_csv(fn)\n",
    "#        data = data.iloc[1:, cols_num]\n",
    "#        data.to_csv(\"temp.csv\", mode='a', header=False, index=False)\n",
    "\n",
    "    # Auto Rename\n",
    "#    os.rename(\"temp.csv\",data.iloc[1,1].split(\"-\")[0] + data.iloc[1,1].split(\"-\")[1] + \".csv\")\n",
    "#    print('Merge Complete')\n",
    "        \n",
    "#    df1 = pd.read_csv(data.iloc[1,1].split(\"-\")[0] + data.iloc[1,1].split(\"-\")[1] + \".csv\")\n",
    "#    df2 = df1.loc[(df1['country'] == country)]\n",
    "\n",
    "    # REMOVE REBUNDANT COUNTRIES\n",
    "    df2 = data.loc[(data['country'] == country)]\n",
    "    \n",
    "    # AGGREGATE BY DAY\n",
    "    # Split date and time\n",
    "    date = df2['date_time'].str.split('-', expand=True)\n",
    "    time = date[2].str.split(' ', expand=True)\n",
    "    split_data = pd.concat([df2, date[[0,1]], time], axis = 1)\n",
    "\n",
    "    # Fill in NaN\n",
    "    split_data.loc[:,'n_crisis'] = split_data.loc[:,'n_crisis'].fillna(5)\n",
    "    split_data.loc[:,'baseline'] = split_data.loc[:,'baseline'].fillna(5)\n",
    "    \n",
    "    # Rename columns\n",
    "    def df_column_uniquify(df):\n",
    "        df_columns = df.columns\n",
    "        new_columns = []\n",
    "        for item in df_columns:\n",
    "            counter = 0\n",
    "            newitem = item\n",
    "            while newitem in new_columns:\n",
    "                counter += 1\n",
    "                newitem = \"{}_{}\".format(item, counter)\n",
    "            new_columns.append(newitem)\n",
    "        df.columns = new_columns\n",
    "        return df\n",
    "\n",
    "    df_column_uniquify(split_data)\n",
    "\n",
    "    split_data.rename(columns={0:\"year\",1:\"month\",\"0_1\":\"day\",\"1_1\":\"time\"}, inplace=True)\n",
    "\n",
    "    # Aggregate by time\n",
    "    aggregate_value = ['n_crisis','difference','baseline']\n",
    "    aggregate = split_data.groupby(['country','start_lat','start_lon','end_lat','end_lon','year','month','day'])[aggregate_value].sum()\n",
    "    aggregate = aggregate.reset_index() # return dataframe of groupby result\n",
    "\n",
    "    # CALCULATE which GRID the trajectory is in, the grid index starts from 0\n",
    "    startgrid_x = []\n",
    "    startgrid_y = []\n",
    "    endgrid_x = []\n",
    "    endgrid_y = []\n",
    "    dif_x = []\n",
    "    dif_y = []\n",
    "\n",
    "    for index, row in aggregate.iterrows():\n",
    "        startgridx = math.floor((row['start_lon'] - 92.25)/0.25)\n",
    "        startgridy = math.floor((28.5 - row['start_lat'])/0.25)\n",
    "        endgridx = math.floor((row['end_lon'] - 92.25)/0.25)\n",
    "        endgridy = math.floor((28.5 - row['end_lat'])/0.25)\n",
    "        difx = abs(startgridx - endgridx)\n",
    "        dify = abs(startgridy - endgridy)\n",
    "\n",
    "        startgrid_x.append(startgridx)\n",
    "        startgrid_y.append(startgridy)\n",
    "        endgrid_x.append(endgridx)\n",
    "        endgrid_y.append(endgridy)\n",
    "        dif_x.append(difx)\n",
    "        dif_y.append(dify)\n",
    "\n",
    "    grid = pd.DataFrame({\"startgrid_x\":startgrid_x,\n",
    "                        \"startgrid_y\":startgrid_y,\n",
    "                        \"endgrid_x\":endgrid_x,\n",
    "                        \"endgrid_y\":endgrid_y,\n",
    "                        \"dif_x\":dif_x,\n",
    "                        \"dif_y\":dif_y})\n",
    "\n",
    "    with_grid = pd.concat([aggregate, grid], axis = 1)\n",
    "\n",
    "    # Filter those data not within one or two adjacent grid\n",
    "    with_grid.drop(with_grid[(with_grid['dif_x']>1) | (with_grid['dif_y']>1)].index,axis=0, inplace = True)\n",
    "\n",
    "    # AGGREGATE BY GRID\n",
    "    aggregate_value = ['n_crisis','difference','baseline']\n",
    "    aggregate2 = with_grid.groupby(['country','year','month','day','startgrid_x','startgrid_y','endgrid_x','endgrid_y'])[aggregate_value].sum()\n",
    "    aggregate2 = aggregate2.reset_index() # return dataframe of groupby result\n",
    "    date = aggregate2['year'].str.cat(aggregate2['month'],sep='-').str.cat(aggregate2['day'],sep='-')\n",
    "    aggregate3 = aggregate2.drop(['year','month','day'], axis = 1)\n",
    "    aggregate3 = pd.concat([aggregate3, date], axis = 1)\n",
    "    aggregate3.rename(columns={\"year\":\"date\"}, inplace=True)\n",
    "\n",
    "    aggregate3.to_csv(\"aggtemp.csv\", mode='a', header=True, index=False)\n",
    "\n",
    "    # Auto rename\n",
    "    os.rename(\"aggtemp.csv\",\"Agg\" + country + aggregate2.iloc[0,1] + aggregate2.iloc[0,2] + \".csv\")\n",
    "    print('Aggregate Complete')\n",
    "    \n",
    "    # assign value to grid\n",
    "    df3 = aggregate3\n",
    "    df3.eval('movement_value = n_crisis / 2' , inplace=True)\n",
    "    df4 = df3.drop([\"endgrid_x\",\"endgrid_y\"], axis = 1)\n",
    "    df5 = df3.drop([\"startgrid_x\",\"startgrid_y\"], axis = 1)\n",
    "    df4.rename(columns={\"startgrid_x\":\"grid_x\", \"startgrid_y\":\"grid_y\"}, inplace = True)\n",
    "    df5.rename(columns={\"endgrid_x\":\"grid_x\", \"endgrid_y\":\"grid_y\"}, inplace = True)\n",
    "    Cal_grid = pd.concat([df4, df5], axis = 0)\n",
    "    Cal_grid = Cal_grid.groupby(['country','date','grid_x','grid_y'])[['n_crisis','difference','baseline','movement_value']].sum()\n",
    "    Cal_grid = Cal_grid.reset_index()\n",
    "\n",
    "    # Assign grid coordinates\n",
    "    Cal_grid['grid_lon'] = Cal_grid['grid_x'].map(lambda x: 92.375 + 0.25*x )\n",
    "    Cal_grid['grid_lat'] = Cal_grid['grid_y'].map(lambda y: 28.375 - 0.25*y )\n",
    "    filepath = \"E:\\GRADUATE STUDY\\GE5219\\Data\\Study Area\\SEA_GRID.csv\"\n",
    "#     coor = pd.read_csv(filepath)\n",
    "#     Cal_grid = Cal_grid.merge(coor,on=['grid_x','grid_y'],how='left')\n",
    "    Cal_grid.to_csv(\"gridtemp.csv\", mode='a', header=True, index=False)\n",
    "    \n",
    "    # Auto rename\n",
    "    os.rename(\"gridtemp.csv\",\"Grid\" + country + aggregate2.iloc[0,1] + aggregate2.iloc[0,2] + \".csv\")\n",
    "    print('Generate Grid Complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0351b6ce",
   "metadata": {},
   "source": [
    "### Auto Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26749066",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Auto_Process(folder_path, country, country_iso2):\n",
    "    folder_path = os.path.abspath(folder_path)\n",
    "    for year in range(2020,2023):\n",
    "        for month in range(1,13):\n",
    "            if year==2020 and month<6:\n",
    "                continue\n",
    "            elif year==2022 and month>2:\n",
    "                break\n",
    "            else:\n",
    "                folder = \"{}{}{:0>2d}\".format(country,year,month)\n",
    "                path = folder_path + \"\\\\\" + folder\n",
    "                Process_File(path, country_iso2)\n",
    "    print(\"Finish processing {}\".format(country))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6437daa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Auto_Process(\"E:\\GRADUATE STUDY\\GE5219\\Data\\Movement\\Processing\", \"Brunei\", \"BN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624c1c98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b515c86f",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Apple Mobility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5a55d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ FILE\n",
    "filepath = r\"E:\\GRADUATE STUDY\\GE5219\\Data\\Movement\\Apple Mobility\\applemobilitytrends-2022-03-10.csv\"\n",
    "df = pd.read_csv(filepath)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffd2c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = ['Singapore','Malaysia','Thailand','Laos','Vietnam','Philippines','Myanmar','Cambodia','Brunei']\n",
    "df2 = df.loc[df['region'].isin(regions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4678956e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfT = pd.DataFrame(df2.values.T, index=df2.columns, columns=df2.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a25fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfT.drop(index = [\"geo_type\",\"alternative_name\",\"sub-region\",\"country\"], inplace = True)\n",
    "dfT.drop(dfT.tail(10).index,inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b036c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b1c85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfT.to_csv(\"applemobility.csv\", header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebafbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"applemobility.csv\"\n",
    "reading = pd.read_csv(filepath)\n",
    "reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae16e092",
   "metadata": {},
   "outputs": [],
   "source": [
    "reading.describe(percentiles=[.2,.75, .8],include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c70330",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "175.68px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
